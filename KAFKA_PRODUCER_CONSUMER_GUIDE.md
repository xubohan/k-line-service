# Kafka ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…å®ç°æŒ‡å—

## ğŸ¯ åŠŸèƒ½å®ç°

æ ¹æ® `producer.txt` å’Œ `listener.txt` çš„æœ€ä½³å®è·µè¦æ±‚ï¼Œå·²å®Œæˆä»¥ä¸‹åŠŸèƒ½ï¼š

### ç”Ÿäº§è€…åŠŸèƒ½ (TestSender)
- âœ… **æŒ‰ç…§æœ€ä½³å®è·µé…ç½®**: å®ç°å¼‚æ­¥å’ŒåŒæ­¥å‘é€åŠŸèƒ½
- âœ… **è¯»å– kafka_data.json**: è‡ªåŠ¨è¯»å– 3600 æ¡è‚¡ç¥¨æ•°æ®
- âœ… **æ¯ç§’å‘é€ä¸€ä¸ªå¯¹è±¡**: ä¸¥æ ¼æŒ‰ç…§æ¯ç§’ä¸€æ¡çš„é€Ÿåº¦å‘é€åˆ° timeline topic
- âœ… **æ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼**: åŒ…è£…ä¸º `{"topic":"timeline", "stock_minute_data":{...}}` æ ¼å¼
- âœ… **å®Œæ•´çš„å›è°ƒå¤„ç†**: æˆåŠŸå’Œå¤±è´¥éƒ½æœ‰ç›¸åº”çš„æ—¥å¿—è®°å½•

### æ¶ˆè´¹è€…åŠŸèƒ½ (TimelineConsumer)
- âœ… **å•æ¡æ¶ˆè´¹æ¨¡å¼**: é…ç½®ä¸º `type: single`ï¼Œä½¿ç”¨ ConsumerRecord å‚æ•°
- âœ… **æ‰‹åŠ¨ ACK**: å®ç° `ack-mode: manual_immediate`ï¼Œç¡®ä¿æ¶ˆæ¯å¤„ç†å®Œæˆåæ‰‹åŠ¨ç¡®è®¤
- âœ… **ä¸¥æ ¼çš„é”™è¯¯å¤„ç†**: æ— æ•ˆæ¶ˆæ¯ä¹Ÿä¼š ACKï¼Œé¿å…æ— é™é‡è¯•
- âœ… **å®Œæ•´çš„æ•°æ®å¤„ç†**: æ¶ˆæ¯éªŒè¯ â†’ æ•°æ®è½¬æ¢ â†’ Redis å­˜å‚¨ â†’ æ‰‹åŠ¨ ACK

## ğŸ“Š æ•°æ®æµç¨‹

```
kafka_data.json (3600æ¡æ•°æ®) 
    â†“ æ¯ç§’è¯»å–ä¸€æ¡
TestSender.sendAllKafkaDataAsync()
    â†“ å‘é€åˆ° timeline topic
Kafka Broker (10.10.80.109:9092)
    â†“ æ¶ˆè´¹è€…è®¢é˜…
TimelineConsumer.run(Acknowledgment ack, ConsumerRecord record)
    â†“ è§£æå¹¶éªŒè¯æ•°æ®
KlineRepository.upsertBatch() + TimelineRedisWriter.write()
    â†“ å­˜å‚¨åˆ° Redis
ack.acknowledge() - æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯å¤„ç†å®Œæˆ
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å¯åŠ¨åº”ç”¨
```bash
cd /Users/bohan/Documents/k-line-service-1
mvn clean package -pl deploy -am -DskipTests
java -jar deploy/target/deploy-0.0.1-SNAPSHOT.jar
```

### 2. å‘é€æ‰€æœ‰ kafka_data.json æ•°æ®ï¼ˆæ¨èï¼‰
```bash
curl -X POST "http://localhost:61851/kafka/send/all-data"
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "code": "0",
  "message": "All kafka data sending started asynchronously (3600 messages)",
  "data": {
    "topic": "timeline",
    "totalMessages": 3600,
    "source": "kafka_data.json",
    "mode": "async",
    "note": "Messages are being sent in background, one per second. Check logs for progress"
  }
}
```

### 3. å‘é€å•æ¡æµ‹è¯•æ¶ˆæ¯
```bash
curl -X POST "http://localhost:61851/kafka/send/test"
```

### 4. æ‰‹åŠ¨å‘é€è‡ªå®šä¹‰æ¶ˆæ¯
```bash
curl -X POST "http://localhost:61851/kafka/send/async" \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "timeline",
    "message": "{\"topic\":\"timeline\", \"stock_minute_data\":{\"stockCode\":\"300033\",\"marketId\":\"33\",\"price\":88.94, \"date\":\"20200101\",\"time\":\"0940\"}}"
  }'
```

## ğŸ“‹ é…ç½®è¯¦æƒ…

### ç”Ÿäº§è€…é…ç½® (application-mq.yml)
```yaml
spring:
  kafka:
    producer:
      acks: 1                    # ä¸»èŠ‚ç‚¹å†™å…¥æˆåŠŸåè¿”å›
      retries: 3                 # å¤±è´¥é‡è¯•æ¬¡æ•°
      batch-size: 16384          # 16KBæ‰¹æ¬¡å¤§å°
      buffer-memory: 33554432    # 32MBå¤„ç†ç¼“å†²åŒº
      properties:
        linger.ms: 100           # æ‰¹æ¬¡ç©ºé—²æ—¶é—´
        request.timeout.ms: 5000 # è¯·æ±‚è¶…æ—¶æ—¶é—´
        max.in.flight.requests.per.connection: 1  # ä¿è¯ä¸¥æ ¼æœ‰åº
```

### æ¶ˆè´¹è€…é…ç½® (application-mq.yml)
```yaml
spring:
  kafka:
    consumer:
      enable-auto-commit: false   # ç¦ç”¨è‡ªåŠ¨æäº¤
      auto-offset-reset: earliest # ä»æœ€æ—©å¼€å§‹æ¶ˆè´¹
      max-poll-records: 50        # æ¯æ¬¡pollæœ€å¤§æ¶ˆæ¯æ¡æ•°
    listener:
      type: single                # å•æ¡æ¶ˆè´¹
      ack-mode: manual_immediate  # æ‰‹åŠ¨ç«‹å³æäº¤ACK
      concurrency: 1             # å•çº¿ç¨‹æ¶ˆè´¹ä¿è¯æœ‰åºæ€§
```

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### ç”Ÿäº§è€…æ—¥å¿—
```
INFO - Starting to send all kafka data (3600 messages) to timeline topic, one per second
INFO - Loaded 3600 messages from kafka_data.json
INFO - Send over. timeline, 0, 12345
INFO - Progress: 100/3600 messages sent
INFO - Finished sending kafka data: 3600 success, 0 errors, 3600 total
```

### æ¶ˆè´¹è€…æ—¥å¿—
```
INFO - Receive Message. Message info: {"topic":"timeline", "stock_minute_data":{...}}
INFO - Consume success. Topic:timeline, Partition:0, Offset:12345
```

## âš™ï¸ æŠ€æœ¯å®ç°è¦ç‚¹

### TestSender å…³é”®ç‰¹æ€§
- **å¼‚æ­¥æ‰§è¡Œ**: ä½¿ç”¨ `@Async` æ³¨è§£ï¼Œé¿å…é˜»å¡ Web è¯·æ±‚
- **ä¸¥æ ¼æ—¶åº**: æ¯ç§’å‘é€ä¸€æ¡æ¶ˆæ¯ï¼Œç¡®ä¿é¡ºåº
- **å®Œæ•´å›è°ƒ**: å®ç°æˆåŠŸå’Œå¤±è´¥çš„å›è°ƒå¤„ç†
- **è¿›åº¦ç›‘æ§**: æ¯100æ¡æ¶ˆæ¯æ‰“å°è¿›åº¦

### TimelineConsumer å…³é”®ç‰¹æ€§
- **æ‰‹åŠ¨ ACK**: æ¶ˆæ¯å¤„ç†å®Œæˆåæ‰è°ƒç”¨ `ack.acknowledge()`
- **é”™è¯¯å®¹å¿**: æ— æ•ˆæ¶ˆæ¯ä¹Ÿä¼š ACKï¼Œé¿å…æ­»å¾ªç¯
- **æ•°æ®éªŒè¯**: ä¸¥æ ¼éªŒè¯æ¶ˆæ¯æ ¼å¼å’Œå­—æ®µ
- **å®Œæ•´å¤„ç†**: æ•°æ®å­˜å‚¨åˆ° Redis åæ‰ç¡®è®¤

## ğŸ“Š æ¶ˆæ¯æ ¼å¼

### å‘é€åˆ° Kafka çš„æ¶ˆæ¯æ ¼å¼
```json
{
  "topic": "timeline",
  "stock_minute_data": {
    "stockCode": "300033",
    "marketId": "33",
    "date": "20200101",
    "price": 88.94,
    "time": "0940"
  }
}
```

### Redis å­˜å‚¨æ ¼å¼
- **ZSet Key**: `kline:1m:33:300033`
- **Score**: æ—¶é—´æˆ³é™¤ä»¥60çš„åˆ†é’Ÿå€¼
- **Member**: ä»·æ ¼å­—ç¬¦ä¸²

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

1. **Kafka è¿æ¥**: ç¡®ä¿ `10.10.80.109:9092` å¯è®¿é—®
2. **è®¤è¯é…ç½®**: ç”¨æˆ·å/å¯†ç ä¸º `test-7`
3. **Topic åˆ›å»º**: éœ€è¦é¢„å…ˆåœ¨ Kafka åˆ›å»º `timeline` topic
4. **é¡ºåºä¿è¯**: ç”Ÿäº§è€…åŒæ­¥å‘é€ + æ¶ˆè´¹è€…å•çº¿ç¨‹å¤„ç†
5. **é”™è¯¯å¤„ç†**: æ¶ˆè´¹è€…ä¼š ACK æ‰€æœ‰æ¶ˆæ¯ï¼ŒåŒ…æ‹¬æ— æ•ˆæ¶ˆæ¯

## ğŸ§ª éªŒè¯æ•°æ®æµç¨‹

1. **å¯åŠ¨åº”ç”¨å¹¶å‘é€æ•°æ®**:
```bash
curl -X POST "http://localhost:61851/kafka/send/all-data"
```

2. **æŸ¥çœ‹æ—¥å¿—ç¡®è®¤æ¶ˆæ¯å‘é€å’Œæ¶ˆè´¹**:
```bash
tail -f logs/application.log | grep -E "(Send over|Consume success)"
```

3. **éªŒè¯æ•°æ®å­˜å‚¨åˆ° Redis**:
```bash
curl "http://localhost:61851/kline?stockcode=300033&marketId=33"
```

---

**å®ç°æ—¶é—´**: 2025å¹´9æœˆ9æ—¥  
**ç¬¦åˆæ ‡å‡†**: producer.txt + listener.txt æœ€ä½³å®è·µ âœ…  
**æ¶ˆæ¯é¡ºåº**: ä¸¥æ ¼æŒ‰ç§’å‘é€ï¼Œå•çº¿ç¨‹æ¶ˆè´¹ âœ…  
**é”™è¯¯å¤„ç†**: å®Œæ•´çš„ç”Ÿäº§è€…å›è°ƒ + æ¶ˆè´¹è€…æ‰‹åŠ¨ACK âœ…